# -*- coding: utf-8 -*-
"""Untitled17.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lqnEndx6qeUBT5lIhh42S3toBgk4FG1k
"""

import os

# Inspect the directory structure
for root, dirs, files in os.walk(path):
    # Only print directories that actually contain files to keep it clean
    if files:
        print(f"Folder: {root}")
        print(f"Sample files: {files[:3]}") # Show first 3 files
        print("-" * 30)

import os
import random
import shutil
import json

# 1. Path setup based on your discovery
path = "/root/.cache/kagglehub/datasets/hendrichscullen/vehide-dataset-automatic-vehicle-damage-detection/versions/1"
output_root = "./vehicle_damage_subset"

# Source paths from your Discovery output
src_train_images = os.path.join(path, 'image', 'image')
src_val_images = os.path.join(path, 'validation', 'validation')
train_json = os.path.join(path, '0Train_via_annos.json')
val_json = os.path.join(path, '0Val_via_annos.json')

# ------------------------------------------
# Step 1: Dataset Overview
# ------------------------------------------
all_train_images = [f for f in os.listdir(src_train_images) if f.endswith(('.jpg', '.jpeg', '.png'))]
all_val_images = [f for f in os.listdir(src_val_images) if f.endswith(('.jpg', '.jpeg', '.png'))]

print(f"Total Train images: {len(all_train_images)}")
print(f"Total Val images: {len(all_val_images)}")

# ------------------------------------------
# Step 2 & 3: Subset Selection
# ------------------------------------------
# Since the dataset is already split, we'll take a subset of both
TRAIN_SUBSET_SIZE = 160
VAL_SUBSET_SIZE = 40

random.seed(42)
selected_train = random.sample(all_train_images, min(TRAIN_SUBSET_SIZE, len(all_train_images)))
selected_val = random.sample(all_val_images, min(VAL_SUBSET_SIZE, len(all_val_images)))

# ------------------------------------------
# Step 4: Folder Structure Creation
# ------------------------------------------


def create_folders():
    # Creating the structure: dataset/images/train, dataset/labels/train, etc.
    subfolders = ['images/train', 'images/val', 'labels/train', 'labels/val']
    for folder in subfolders:
        os.makedirs(os.path.join(output_root, folder), exist_ok=True)

create_folders()

def move_images(file_list, src_dir, folder_type):
    count = 0
    for filename in file_list:
        src_path = os.path.join(src_dir, filename)
        dest_path = os.path.join(output_root, 'images', folder_type, filename)
        shutil.copy2(src_path, dest_path)
        count += 1
    return count

# Move the subset images
train_count = move_images(selected_train, src_train_images, 'train')
val_count = move_images(selected_val, src_val_images, 'val')

# Copy the JSON labels into the labels folder
shutil.copy2(train_json, os.path.join(output_root, 'labels', 'train', 'annotations.json'))
shutil.copy2(val_json, os.path.join(output_root, 'labels', 'val', 'annotations.json'))

print(f"\n--- Subset Preparation Complete ---")
print(f"Images moved: {train_count} train, {val_count} val")
print(f"Labels: JSON annotation files copied to labels/train and labels/val")

import json
import os

# Function to keep only the 200 selected images in the JSON metadata
def filter_json_annotations(json_path, selected_filenames):
    with open(json_path, 'r') as f:
        data = json.load(f)

    filtered_data = {}

    # We use 'name' because your "Peek" step confirmed that is the key used
    for key, value in data.items():
        if isinstance(value, dict) and 'name' in value:
            if value['name'] in selected_filenames:
                filtered_data[key] = value

    with open(json_path, 'w') as f:
        json.dump(filtered_data, f)

    return len(filtered_data)

# Define the paths to the JSON files inside your NEW subset folder
train_json_subset = os.path.join(output_root, 'labels/train/annotations.json')
val_json_subset = os.path.join(output_root, 'labels/val/annotations.json')

# Run the filtering
final_train_count = filter_json_annotations(train_json_subset, selected_train)
final_val_count = filter_json_annotations(val_json_subset, selected_val)

print(f"--- Data Cleanliness Check ---")
print(f"Train annotations successfully filtered to: {final_train_count}")
print(f"Val annotations successfully filtered to: {final_val_count}")

import json

# Let's peek at the first entry of the training JSON
json_path = os.path.join(output_root, 'labels/train/annotations.json')
with open(json_path, 'r') as f:
    data = json.load(f)

# Get the first key and its contents
first_key = list(data.keys())[0]
print(f"First Key in JSON: {first_key}")
print(f"Content of that key: {data[first_key]}")

import matplotlib.pyplot as plt
import cv2
import json

# Load one image and its labels from your NEW subset
sample_img_name = selected_train[0]
img_path = os.path.join(output_root, 'images/train', sample_img_name)
json_path = os.path.join(output_root, 'labels/train/annotations.json')

with open(json_path, 'r') as f:
    annotations = json.load(f)

# Find the annotation for this specific image
# Note: In your JSON, the key might be the filename itself
anno = annotations.get(sample_img_name)

img = cv2.imread(img_path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

plt.figure(figsize=(10, 10))
plt.imshow(img)

# Plot the polygon points
for region in anno['regions']:
    x = region['all_x']
    y = region['all_y']
    plt.plot(x, y, 'r-', linewidth=2) # Draw red line
    plt.scatter(x, y, s=10, color='yellow') # Draw yellow dots at corners

plt.title(f"Verifying Labels: {sample_img_name}")
plt.axis('off')
plt.show()

import json
import os

# Define the class mapping based on your dataset
class_map = {'mat_bo_phan': 0, 'rach': 1, 'mop_lom': 2, 'tray_son': 3}

def via_to_yolo(subset_type):
    json_path = f"./vehicle_damage_subset/labels/{subset_type}/annotations.json"
    img_dir = f"./vehicle_damage_subset/images/{subset_type}"
    label_dir = f"./vehicle_damage_subset/labels/{subset_type}"

    with open(json_path, 'r') as f:
        data = json.load(f)

    for key, value in data.items():
        filename = value['name']
        img_path = os.path.join(img_dir, filename)

        # Get image dimensions to normalize coordinates
        img = cv2.imread(img_path)
        if img is None: continue
        h, w, _ = img.shape

        yolo_annotations = []
        for region in value['regions']:
            cls_name = region['class']
            cls_id = class_map.get(cls_name, 0)

            # Convert polygon to bounding box
            x_coords = region['all_x']
            y_coords = region['all_y']
            xmin, xmax = min(x_coords), max(x_coords)
            ymin, ymax = min(y_coords), max(y_coords)

            # YOLO format: class x_center y_center width height (normalized 0-1)
            bw = (xmax - xmin) / w
            bh = (ymax - ymin) / h
            cx = (xmin + (xmax - xmin) / 2) / w
            cy = (ymin + (ymax - ymin) / 2) / h

            yolo_annotations.append(f"{cls_id} {cx} {cy} {bw} {bh}")

        # Save to .txt file
        txt_filename = os.path.splitext(filename)[0] + ".txt"
        with open(os.path.join(label_dir, txt_filename), 'w') as f:
            f.write("\n".join(yolo_annotations))

# Run conversion for both
via_to_yolo('train')
via_to_yolo('val')
print("Labels converted to YOLO format successfully!")

!pip install ultralytics

# ==========================================
# Week 4 – Evaluation & Error Analysis
# ==========================================
# Step 1: Import required libraries
try:
    from ultralytics import YOLO
except ImportError:
    print("Ultralytics not found. Please run: !pip install ultralytics")

import matplotlib.pyplot as plt
import cv2
import os
import random

# ------------------------------------------
# Step 1: Load Trained Model
# ------------------------------------------
# We load the 'nano' model. In a full project, you would use your
# 'best.pt' file from the training phase.
model = YOLO('yolov8n.pt')
print("Model loaded successfully.")

# ------------------------------------------
# Step 2: Run Inference on Validation Images
# ------------------------------------------
# Using the subset we created in the previous step
val_images_path = "./vehicle_damage_subset/images/val"
val_images = [os.path.join(val_images_path, f) for f in os.listdir(val_images_path) if f.endswith(('.jpg', '.png'))]

# Select 3 random validation images
test_samples = random.sample(val_images, min(3, len(val_images)))
results = model(test_samples)

# ------------------------------------------
# Step 3: Visualize Predictions
# ------------------------------------------
for result in results:
    # plot() returns the image with boxes and confidence scores
    annotated_img = result.plot()
    annotated_img = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)

    plt.figure(figsize=(10, 6))
    plt.imshow(annotated_img)
    plt.title(f"Inference: {os.path.basename(result.path)}")
    plt.axis('off')
    plt.show()

# ------------------------------------------
# Step 4: Understanding Metrics
# ------------------------------------------
# These are the standard industry metrics for YOLOv8
print("\n--- Evaluation Metrics Explanation ---")
print("1. IoU (Intersection over Union): Measures how much the predicted box overlaps the actual label.")
print("2. Precision: Of all predicted damages, how many were correct? (Reduces False Positives)")
print("3. Recall: Of all real damages, how many did the model find? (Reduces False Negatives)")
print("4. mAP50: The mean Average Precision calculated at 0.5 IoU threshold.")



# ------------------------------------------
# Step 5: Error Analysis
# ------------------------------------------
# Failure Case Identification
print("\n--- Common Failure Cases to Identify ---")
print("- False Positive: Model flags a shadow, reflection, or license plate as 'damage'.")
print("- False Negative: Model misses small scratches (common in low light).")
print("- Localization Error: The box is correct, but it doesn't tightly fit the damage.")

# ------------------------------------------
# Step 4: Quantitative Evaluation (Metrics)
# ------------------------------------------

# 1. Create a data.yaml file (YOLO needs this to find your images/labels)
import yaml

data_config = {
    'train': os.path.abspath('./vehicle_damage_subset/images/train'),
    'val': os.path.abspath('./vehicle_damage_subset/images/val'),
    'nc': 4,
    'names': ['mat_bo_phan', 'rach', 'mop_lom', 'tray_son']
}

with open('vehicle_damage.yaml', 'w') as f:
    yaml.dump(data_config, f)

# 2. Run the validation engine
# This is what actually calculates the Precision, Recall, and mAP
metrics = model.val(data='vehicle_damage.yaml')

print("\n--- Final Calculated Metrics ---")
# Use the results_dict keys directly
results = metrics.results_dict
print(f"Mean Average Precision (mAP@50): {results.get('metrics/mAP50(B)', 0):.4f}")
print(f"Precision: {results.get('metrics/precision(B)', 0):.4f}")
print(f"Recall: {results.get('metrics/recall(B)', 0):.4f}")

import yaml
import os

# Define the dataset configuration
data_config = {
    'path': os.path.abspath('./vehicle_damage_subset'), # Path to your subset folder
    'train': 'images/train',
    'val': 'images/val',
    'nc': 4,
    'names': ['mat_bo_phan', 'rach', 'mop_lom', 'tray_son'] # Your 4 Vietnamese classes
}

with open('vehicle_damage.yaml', 'w') as f:
    yaml.dump(data_config, f)

print("vehicle_damage.yaml created successfully!")

from ultralytics import YOLO

# Load the base model
model = YOLO('yolov8n.pt')

# Start training
# epochs: How many times the model sees the whole dataset
# imgsz: Image size (640 is standard)
# batch: How many images to process at once
results = model.train(
    data='vehicle_damage.yaml',
    epochs=20,
    imgsz=640,
    batch=8,
    name='vehicle_damage_run'
)

# Load your NEWLY trained best model
best_model = YOLO('./runs/detect/vehicle_damage_run/weights/best.pt')

# Run validation
final_metrics = best_model.val()

print("\n--- NEW Post-Training Metrics ---")
res = final_metrics.results_dict
print(f"New mAP@50: {res.get('metrics/mAP50(B)', 0):.4f}")
print(f"New Precision: {res.get('metrics/precision(B)', 0):.4f}")
print(f"New Recall: {res.get('metrics/recall(B)', 0):.4f}")

!pip install ultralytics

# ==========================================
# Week 4 – Training an Object Detector
# ==========================================
# Step 1: Import required libraries
# !pip install ultralytics # Run this if not already installed

from ultralytics import YOLO
import os
import yaml

# ------------------------------------------
# Step 2: Dataset Configuration
# ------------------------------------------
# We define the configuration for the YOLO model
dataset_root = os.path.abspath("./vehicle_damage_subset")

data_config = {
    'path': dataset_root,
    'train': 'images/train',
    'val': 'images/val',
    'nc': 4,
    'names': ['mat_bo_phan', 'rach', 'mop_lom', 'tray_son'] # Classes from your JSON labels
}

# Save as vehicle_damage.yaml
with open('vehicle_damage.yaml', 'w') as f:
    yaml.dump(data_config, f)

print("Dataset configuration YAML created.")